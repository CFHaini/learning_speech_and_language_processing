{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f6944f",
   "metadata": {},
   "source": [
    "## Encoder - Decoder\n",
    "现有的预训练模型有 **只基于Encoder**的BERT 和 **只基于Decoder**的GPT \n",
    "### 1.1 Seq2Seq\n",
    "**Seq2Seq**，即序列到序列，即模型输入的是一个自然语言序列，输出是一个可能不等长的自然语言序列。\n",
    "- 典型应用：机器翻译、文本摘要、对话系统等 几乎所有的NLP任务都可以视为Seq2Seq任务\n",
    "\n",
    "在Seq2Seq任务中，一般思路为：\n",
    "- **编码**，将输入的自然语言序列通过隐藏层编码为能够表征语义的向量\n",
    "- **解码**，将向量通过隐藏层输出，再解码为自然语言序列。\n",
    "\n",
    "**Transformer中的Encoder -> 编码 ，Decoder -> 解码** ？？？\n",
    "### 1.2 前馈神经网络\n",
    "前馈神经网络网络的特点是：\n",
    "- 信息流是单向传播的\n",
    "- 最重要的是有**激活函数**来保证前馈神经网络能够拟合任意函数形式，而不是**线性回归的堆叠**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72f42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,resid_pdrop=0.1):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size,output_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(resid_pdrop)\n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.linear2(self.activation(self.linear1(x))))\n",
    " #该前馈神经网络是由两个线性层中间加一个 GELU 激活函数组成的，以及前馈神经网络还加入了一个 Dropout 层来防止过拟合       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4cd1ba",
   "metadata": {},
   "source": [
    "## 1.3 层归一化 (LayerNorm)\n",
    "归⼀化核⼼是为了让不同层输⼊的取值范围或者分布能够⽐较⼀致。主流归一化有两种：批归一化(batch Norm)和层归一化(Layer Norm)\n",
    "\n",
    "批归一化 是 计算一个batch_size的样本中的 每个特征维度d上的均值和方差\n",
    "\n",
    "层归一化是计算每一个token中的特征维度的均值和方差，只看属于自己的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13afd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,size,eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.eps=eps\n",
    "        self.a = nn.Parameter(torch.ones(size))\n",
    "        self.b = nn.Parameter(torch.zeros(size))#可学习参数\n",
    "    def forward(self,x):\n",
    "        mean =x.mean(-1,keepdim=True) # x的维度为B，T，C\n",
    "        #mean的维度为B，T，1\n",
    "        std =x.std(-1,keepdim=True)\n",
    "        #std的维度亦为B，T，1\n",
    "        return self.a*(x-mean)/(std+self.eps)+self.b\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb730cca",
   "metadata": {},
   "source": [
    "## 1.4 残差连接\n",
    "由于Transformer模型的结果较复杂，为了避免模型退化，减少梯度消失的情况，引入了残差连接的思想。\n",
    "即将上一层的输入与下一层的输出结合起来，以允许最底层的信息传递到最高层\n",
    "\n",
    "同时注意在每进入一个模块时都需要对数据进行 归一化和残差连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967ce9d",
   "metadata": {},
   "source": [
    "## 1.5 Encoder\n",
    "Encoder 由 N 个 Encoder Layer 组成，\n",
    "每⼀个 Encoder Layer 包括⼀个注意⼒层和⼀个前馈神经⽹络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087265c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EncoderLayer(nn.Module):\n",
    "    '''Encoder layer block'''\n",
    "    def __init__(self,n_emdb,n_head,hidden_size,attn_pdrop=0.1,resid_pdrop=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.ln_1 = LayerNorm(n_emdb)\n",
    "        self.ln_2 = LayerNorm(n_emdb)\n",
    "        self.attn = MultiHeadAttention(n_emdb,n_head,attn_pdrop,resid_pdrop)\n",
    "        self.mlp = MLP(n_emdb,hidden_size,n_emdb,resid_pdrop)\n",
    "    def forward(self,x,mask=None):\n",
    "        x = x +self.attn(self.ln_1(x),mask=mask)\n",
    "        x= x + self.mlp(self.ln_2(x))\n",
    "        return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f96bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,n_emdb,n_head,n_layer,hidden_size,attn_pdrop=0.1,resid_pdrop=0.1):\n",
    "        '''Encoder block'''\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderLayer(n_emdb,n_head,hidden_size,attn_pdrop,resid_pdrop) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.ln_f = LayerNorm(n_emdb)\n",
    "    def forward(self,x,mask=None):\n",
    "        for layer in self.layers:\n",
    "            x= layer(x,mask=mask)\n",
    "        return self.ln_f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f281d5",
   "metadata": {},
   "source": [
    "## 1.6 Decoder\n",
    "Decoder包含两个注意力层\n",
    "第⼀个注意⼒层是⼀个掩码⾃注意⼒层，即使⽤ Mask 的注意⼒计算，保证每⼀个 token 只能使⽤该 token 之前的注意⼒分数；\n",
    "第⼆个注意⼒层是⼀个多头注意⼒层，该层将使⽤第⼀个注意⼒层的输出作为 query，使⽤ Encoder 的输出作为 key 和 value，来计算注意⼒分数\n",
    "\n",
    "我发现原来写的MultiHeadAttention并不能与上面的要求接口相对齐，所以实现细节和实现接口先不管了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e08bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DecoderLayer(nn.Module):\n",
    "    '''Decoder layer block'''\n",
    "    def __init__(self,n_embd,n_head,hidden_size,attn_pdrop=0.1,resid_pdrop=0.1):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.ln_1 = LayerNorm(n_embd)\n",
    "        self.ln_2 = LayerNorm(n_embd)\n",
    "        self.ln_3 = LayerNorm(n_embd)\n",
    "        self.self_attn = MultiHeadAttention(n_embd,n_head,attn_pdrop,resid_pdrop)\n",
    "        self.cross_attn = MultiHeadAttention(n_embd,n_head,attn_pdrop,resid_pdrop)\n",
    "        self.mlp = MLP(n_embd,hidden_size,n_embd,resid_pdrop)\n",
    "    def forward(self,x,enc_out,cross_attn_mask=None,attn_mask=None):\n",
    "        x= x + self.self_attn(self.ln_1(x),mask=attn_mask)\n",
    "        x = x + self.cross_attn(self.ln_2(x),kv = enc_out,mask = cross_attn_mask)\n",
    "        x = x + self.mlp(self.ln_3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f72d8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,n_embd,n_head,n_layer,hidden_size,attn_pdrop=0.1,resid_pdrop=0.1):\n",
    "        '''Decoder block'''\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderLayer(n_embd,n_head,hidden_size,attn_pdrop,resid_pdrop) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.ln_f = LayerNorm(n_embd)\n",
    "    def forward(self,x,enc_out,cross_attn_mask=None,attn_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x= layer(x,enc_out,cross_attn_mask,attn_mask)\n",
    "        return self.ln_f(x)\n",
    "    #该解码器块由多个解码器层组成，每个解码器层包含自注意力机制、交叉注意力机制和前馈神经网络，并在每个子层之后应用层归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2af11e",
   "metadata": {},
   "source": [
    "**可以看出上述的encoder与decoder的融合是按这张图片的逻辑**\n",
    "![可以看出上述的encoder与decoder的融合是按这张图片的逻辑](../imgae/2-0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c647a9e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
